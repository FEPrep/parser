{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pymupdf\n",
    "\n",
    "from parser.elements.rectangle import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser.elements.pymupdf_integ import load_exam_and_extract_text_words\n",
    "\n",
    "load_exam_and_extract_text_words(\"../fe_files/exams/FE-Jan24.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # noqa: F811\n",
    "import re\n",
    "from typing import Dict, Tuple  # noqa: F811\n",
    "\n",
    "import pymupdf  # type: ignore # noqa: F811\n",
    "import regex  # type: ignore\n",
    "\n",
    "from parser.dataset.dataloader import DataLoader\n",
    "from parser.dataset.exam import get_semester_and_year\n",
    "from parser.elements.fill_in_the_blank import separate_underscores_from_text\n",
    "from parser.elements.page import (\n",
    "    ExamResult,\n",
    "    MacroDefinition,\n",
    "    PageBlocks,\n",
    "    PageResult,\n",
    "    Question,\n",
    "    StructDefinition,\n",
    "    extract_macro_definitions,\n",
    "    extract_struct_definitions,\n",
    "    is_code_page,\n",
    ")\n",
    "from parser.elements.pymupdf_integ import PyMuPDFRect, mark_rect, rect_to_bbox\n",
    "from parser.elements.rectangle import merge_rectangles\n",
    "from parser.model.page_model import PageType, SectionType, Semester\n",
    "from parser.page_processing import (\n",
    "    extract_date_from_page,\n",
    "    get_page_type,\n",
    "    get_section_type,\n",
    ")\n",
    "from parser.question_extraction import apply_header_filter\n",
    "\n",
    "\n",
    "def remove_page_mentions(text: str) -> str:\n",
    "    # Use regular expression to find and remove \"Page x of y\" patterns\n",
    "    return re.sub(r\"Page \\d+ of \\d+\", \"\", text)\n",
    "\n",
    "\n",
    "def load_exam_and_extract_text_words(\n",
    "    filepath: str, write_files: bool = False\n",
    ") -> ExamResult:\n",
    "    doc: pymupdf.Document = pymupdf.open(filepath)\n",
    "\n",
    "    semester: Semester | None = None\n",
    "    year: int | None = None\n",
    "    page_results: List[PageResult] = []\n",
    "\n",
    "    previous_section_type: SectionType | None = None\n",
    "    for i, page in enumerate(doc):  # scan through the pages\n",
    "        blocks: List[PyMuPDFRect] = page.get_text(\"words\")\n",
    "        page_blocks = PageBlocks.from_page_bboxes(blocks, page)\n",
    "\n",
    "        if previous_section_type is None:\n",
    "            assert i == 0\n",
    "            date = extract_date_from_page(page_blocks.merged_text)\n",
    "            assert date is not None\n",
    "            semester, year = get_semester_and_year(date)\n",
    "\n",
    "        page_type = get_page_type(page_blocks.merged_text)\n",
    "        if page_type is None:\n",
    "            print(f\"Breaking on page {i} because it is not a valid PageType\")\n",
    "            break\n",
    "\n",
    "        section_type: SectionType | None = None\n",
    "        if page_type == PageType.SECTION:\n",
    "            section_type = get_section_type(page_blocks.merged_text)\n",
    "            if section_type is None:\n",
    "                print(f\"Breaking on page {i} because it is not a valid SectionType\")\n",
    "                print(page_blocks.merged_text)\n",
    "                break\n",
    "        else:\n",
    "            section_type = previous_section_type\n",
    "\n",
    "        if section_type is None:\n",
    "            raise ValueError(\"section_type is None\")\n",
    "\n",
    "        if page_type == PageType.SECTION:\n",
    "            page_result = PageResult(\n",
    "                page_number=i,\n",
    "                section_type=section_type,\n",
    "                page_type=page_type,\n",
    "                raw_text=page_blocks.merged_text,\n",
    "                filtered_text=remove_page_mentions(page_blocks.merged_text),\n",
    "                code_areas=[],\n",
    "                fill_in_the_blank_areas=[],\n",
    "                struct_definitions=[],\n",
    "                macro_definitions=[],\n",
    "            )\n",
    "            page_results.append(page_result)\n",
    "            previous_section_type = section_type\n",
    "\n",
    "            continue\n",
    "\n",
    "        underscore_marking_queue: List[Rectangle] = []\n",
    "\n",
    "        for block in page_blocks.blocks:\n",
    "            rectangle = Rectangle.from_points(*block[0:4])\n",
    "            rect_text = block[4]\n",
    "            separated = separate_underscores_from_text(page, rectangle, rect_text)\n",
    "            if separated.underscores is not None:\n",
    "                underscore_marking_queue.append(separated.underscores)\n",
    "\n",
    "        is_code, code_areas = is_code_page(page, page_blocks)\n",
    "        print(f\"is_code={is_code}\")\n",
    "\n",
    "        if is_code:\n",
    "            assert code_areas is not None\n",
    "            for code_area in code_areas:\n",
    "                # assert len(code_area.sub_areas) > 0\n",
    "                print(f\"underscore_marking_queue={underscore_marking_queue}\")\n",
    "\n",
    "                mark_rect(page, code_area.rect, \"entire_function_area\")\n",
    "\n",
    "                for underscore in underscore_marking_queue:\n",
    "                    underscore_rect = Rectangle.from_points(*rect_to_bbox(underscore))\n",
    "                    if underscore_rect.is_within(code_area.rect):\n",
    "                        # remove the underscore from the queue\n",
    "                        mark_rect(page, underscore_rect, \"code_underscores\")\n",
    "                        print(f\"Removed underscore from queue: {underscore}\")\n",
    "                        underscore_marking_queue.remove(underscore)\n",
    "\n",
    "                for area in code_area.sub_areas:\n",
    "                    mark_rect(page, area.code_textarea, \"code_textarea\")\n",
    "\n",
    "            if write_files:\n",
    "                with open(f\"page-{i}-code_areas.json\", \"w\") as code_file:\n",
    "                    json.dump(\n",
    "                        [code_area.model_dump() for code_area in code_areas],\n",
    "                        code_file,\n",
    "                        indent=4,\n",
    "                    )\n",
    "\n",
    "        for underscore in underscore_marking_queue:\n",
    "            mark_rect(\n",
    "                page,\n",
    "                Rectangle.from_points(*rect_to_bbox(underscore)),\n",
    "                \"code_underscores\",\n",
    "            )\n",
    "\n",
    "        struct_definitions: List[StructDefinition] = extract_struct_definitions(\n",
    "            page, page_blocks\n",
    "        )\n",
    "\n",
    "        for struct_definition in struct_definitions:\n",
    "            mark_rect(page, struct_definition.rect, \"struct_definition\")\n",
    "\n",
    "        macro_definitions: List[MacroDefinition] = extract_macro_definitions(\n",
    "            page, page_blocks\n",
    "        )\n",
    "\n",
    "        for macro_definition in macro_definitions:\n",
    "            mark_rect(page, macro_definition.rect, \"macro_definition\")\n",
    "\n",
    "        page_result = PageResult(\n",
    "            page_number=i,\n",
    "            section_type=section_type,\n",
    "            page_type=page_type,\n",
    "            code_areas=code_areas if code_areas is not None else [],\n",
    "            filtered_text=remove_page_mentions(page_blocks.merged_text),\n",
    "            fill_in_the_blank_areas=[\n",
    "                Rectangle.from_points(*rect_to_bbox(x))\n",
    "                for x in underscore_marking_queue\n",
    "                if x is not None\n",
    "            ],\n",
    "            raw_text=page_blocks.merged_text,\n",
    "            struct_definitions=struct_definitions,\n",
    "            macro_definitions=macro_definitions,\n",
    "        )\n",
    "\n",
    "        previous_section_type = section_type\n",
    "        page_results.append(page_result)\n",
    "\n",
    "    questions: Dict[Tuple[SectionType, int], Question] = parse_into_questions(\n",
    "        page_results, doc\n",
    "    )\n",
    "\n",
    "    def transform_questions(\n",
    "        questions: Dict[Tuple[SectionType, int], Question],\n",
    "    ) -> Dict[SectionType, Dict[int, Question]]:\n",
    "        return {k[0]: {k[1]: v} for k, v in questions.items()}\n",
    "\n",
    "    transformed_questions: Dict[SectionType, Dict[int, Question]] = transform_questions(\n",
    "        questions\n",
    "    )\n",
    "\n",
    "    for transformed_question in transformed_questions.values():\n",
    "        for question in transformed_question.values():\n",
    "            for page_number, rect in question.rects.items():\n",
    "                page = doc.load_page(page_number)\n",
    "                print(f\"Marking question on page {page_number}, rect: {rect}\")\n",
    "                mark_rect(page, rect, \"question\")\n",
    "\n",
    "    if write_files:\n",
    "        doc.save(\"marked-\" + os.path.basename(filepath))\n",
    "\n",
    "    return ExamResult(\n",
    "        semester=semester,\n",
    "        year=year,\n",
    "        page_results=page_results,\n",
    "        questions=transformed_questions,\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_questions(text: str) -> List[Question]:\n",
    "    questions: List[Question] = []\n",
    "    pattern = re.compile(\n",
    "        r\"(?s)\\s*([1-5])\\)\\s*\\((\\d+)\\s*pts\\)\\s*([\\w/ ]+)\\s*\\(\\s*([^)]+?)\\s*\\)\\s*(.*?)(?=\\s*[1-5]\\)\\s*\\(\\d+\\s*pts\\)\\s*[\\w/ ]+\\s*\\([^)]+\\)|\\s*\\Z)\",\n",
    "        re.DOTALL,\n",
    "    )\n",
    "\n",
    "    matches = pattern.findall(text)\n",
    "\n",
    "    for match in matches:\n",
    "        question_number, max_points, category, sub_category, question_text = match\n",
    "\n",
    "        question = Question(\n",
    "            rects={},\n",
    "            raw=question_text,\n",
    "            sub_questions=[],\n",
    "            question_number=int(question_number),\n",
    "        )\n",
    "\n",
    "        questions.append(question)\n",
    "\n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_into_questions(\n",
    "    page_results: List[PageResult], pymupdf_doc: pymupdf.Document\n",
    ") -> Dict[Tuple[SectionType, int], Question]:\n",
    "    pymupdf_pages = load_pymupdf_pages(pymupdf_doc, len(page_results))\n",
    "    questions = {}\n",
    "\n",
    "    for i, page_result in enumerate(page_results):\n",
    "        if should_skip_page(page_result, i, page_results):\n",
    "            continue\n",
    "\n",
    "        current_page_text = page_result.filtered_text\n",
    "        current_page_questions = extract_questions_from_page(current_page_text)\n",
    "        next_page_text = get_next_page_text(i, page_results)\n",
    "        current_plus_next_page_questions = extract_questions_from_combined_text(\n",
    "            current_page_text, next_page_text\n",
    "        )\n",
    "\n",
    "        process_current_page_questions(questions, page_result, current_page_questions)\n",
    "        process_combined_page_questions(\n",
    "            questions, pymupdf_pages, i, page_result, current_plus_next_page_questions\n",
    "        )\n",
    "\n",
    "    return questions\n",
    "\n",
    "\n",
    "def load_pymupdf_pages(\n",
    "    pymupdf_doc: pymupdf.Document, num_pages: int\n",
    ") -> List[pymupdf.Page]:\n",
    "    return [pymupdf_doc.load_page(i) for i in range(num_pages)]\n",
    "\n",
    "\n",
    "def should_skip_page(\n",
    "    page_result: PageResult, i: int, page_results: List[PageResult]\n",
    ") -> bool:\n",
    "    if page_result.page_type == PageType.SECTION:\n",
    "        print(f\"Skipping page {i} because it is a section\")\n",
    "        return True\n",
    "    if i + 1 < len(page_results) and page_results[i + 1].page_type == PageType.SECTION:\n",
    "        print(f\"Skipping page {i} because next page is a section\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_questions_from_page(current_page_text: str) -> List[Question]:\n",
    "    return extract_questions(apply_header_filter(current_page_text))\n",
    "\n",
    "\n",
    "def get_next_page_text(i: int, page_results: List[PageResult]) -> str:\n",
    "    return page_results[i + 1].filtered_text if i + 1 < len(page_results) else \"\"\n",
    "\n",
    "\n",
    "def extract_questions_from_combined_text(\n",
    "    current_page_text: str, next_page_text: str\n",
    ") -> List[Question]:\n",
    "    next_plus_current = apply_header_filter(current_page_text) + (\n",
    "        \"\\n\" + apply_header_filter(next_page_text) if next_page_text != \"\" else \"\"\n",
    "    )\n",
    "    return extract_questions(next_plus_current)\n",
    "\n",
    "\n",
    "def process_current_page_questions(\n",
    "    questions: Dict[Tuple[SectionType, int], Question],\n",
    "    page_result: PageResult,\n",
    "    current_page_questions: List[Question],\n",
    "):\n",
    "    for question in current_page_questions:\n",
    "        questions[(page_result.section_type, question.question_number)] = question\n",
    "\n",
    "\n",
    "def process_combined_page_questions(\n",
    "    questions: Dict[Tuple[SectionType, int], Question],\n",
    "    pymupdf_pages: List[pymupdf.Page],\n",
    "    i: int,\n",
    "    page_result: PageResult,\n",
    "    current_plus_next_page_questions: List[Question],\n",
    "):\n",
    "    for question in current_plus_next_page_questions:\n",
    "        key = (page_result.section_type, question.question_number)\n",
    "        if key in questions:\n",
    "            existing_question = questions[key]\n",
    "            if existing_question.raw != question.raw:\n",
    "                update_question_for_multi_page(\n",
    "                    questions, pymupdf_pages, i, key, existing_question, question\n",
    "                )\n",
    "            else:\n",
    "                update_question_for_single_page(\n",
    "                    questions, pymupdf_pages, i, key, existing_question\n",
    "                )\n",
    "\n",
    "\n",
    "def update_question_for_multi_page(\n",
    "    questions: Dict[Tuple[SectionType, int], Question],\n",
    "    pymupdf_pages: List[pymupdf.Page],\n",
    "    i: int,\n",
    "    key: Tuple[SectionType, int],\n",
    "    existing_question: Question,\n",
    "    question: Question,\n",
    "):\n",
    "    current_pymupdf_page = pymupdf_pages[i]\n",
    "    current_page_rect = find_rectangles(current_pymupdf_page, existing_question.raw)\n",
    "    text_difference = question.raw[len(existing_question.raw) :]\n",
    "    next_page = pymupdf_pages[i + 1]\n",
    "    next_page_rect = find_rectangles(next_page, text_difference)\n",
    "    questions[key].raw = question.raw\n",
    "    questions[key].rects = {i: current_page_rect, i + 1: next_page_rect}\n",
    "\n",
    "\n",
    "def update_question_for_single_page(\n",
    "    questions: Dict[Tuple[SectionType, int], Question],\n",
    "    pymupdf_pages: List[pymupdf.Page],\n",
    "    i: int,\n",
    "    key: Tuple[SectionType, int],\n",
    "    existing_question: Question,\n",
    "):\n",
    "    current_pymupdf_page = pymupdf_pages[i]\n",
    "    current_page_rect = find_rectangles_with_fallback(\n",
    "        current_pymupdf_page, existing_question.raw\n",
    "    )\n",
    "    questions[key].rects = {i: current_page_rect}\n",
    "\n",
    "\n",
    "def find_rectangles(page: pymupdf.Page, text: str) -> Rectangle:\n",
    "    return merge_rectangles(\n",
    "        [Rectangle.from_points(*x[0:4]) for x in page.search_for(text)]\n",
    "    )\n",
    "\n",
    "\n",
    "def find_rectangles_with_fallback(page: pymupdf.Page, text: str) -> Rectangle:\n",
    "    try:\n",
    "        return find_rectangles(page, text)\n",
    "    except Exception:\n",
    "        print(f\"Error finding rectangles for text: {text}\")\n",
    "        print(\"Attempting alternative approach\")\n",
    "        first_line = text.split(\"\\n\")[0].strip()\n",
    "        last_line = [line for line in text.split(\"\\n\") if line.strip()][-1].strip()\n",
    "        try:\n",
    "            return merge_rectangles(\n",
    "                [Rectangle.from_points(*x[0:4]) for x in page.search_for(first_line)]\n",
    "                + [Rectangle.from_points(*x[0:4]) for x in page.search_for(last_line)]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding rectangles with fallback: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_ALL = True\n",
    "\n",
    "\n",
    "def serialize_questions(questions: Dict[int, Question], filepath: str):\n",
    "    out_dir = os.path.join(\"test_data\", os.path.basename(filepath.replace(\".pdf\", \"\")))\n",
    "    os.makedirs(\"test_data\", exist_ok=True)\n",
    "    with open(f\"{out_dir}-questions.json\", \"w\") as questions_file:\n",
    "        json.dump(questions, questions_file, indent=4)\n",
    "\n",
    "\n",
    "if LOAD_ALL:\n",
    "    loader = DataLoader(\"../fe_files/exams/\", \"../fe_files/solutions/\")\n",
    "    exam_paths = loader.get_exam_paths()\n",
    "\n",
    "    for exam_path in exam_paths:\n",
    "        print(f\"Processing {exam_path}\")\n",
    "        exam_results = load_exam_and_extract_text_words(exam_path, write_files=True)\n",
    "\n",
    "        # pymupdf_doc = pymupdf.open(exam_path)\n",
    "        # questions: Dict[Tuple[SectionType, int], Question] = parse_into_questions(\n",
    "        #    page_results, pymupdf_doc\n",
    "        # )\n",
    "\n",
    "        # serialize_questions(exam_results)\n",
    "        # serialize_questions(\n",
    "        #    {f\"{k[0]}-{k[1]}\": v.model_dump() for k, v in questions.items()}, exam_path\n",
    "        # )\n",
    "\n",
    "else:\n",
    "    load_exam_and_extract_text_words(\"../fe_files/exams/FE-Jan20.pdf\", write_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from parser.elements.code import CodeArea\n",
    "\n",
    "\n",
    "def get_all_exam_results() -> Dict[str, ExamResult]:\n",
    "    loader = DataLoader(\"../fe_files/exams/\", \"../fe_files/solutions/\")\n",
    "    exam_paths = loader.get_exam_paths()\n",
    "\n",
    "    exam_results: Dict[str, ExamResult] = {}\n",
    "    for exam_path in exam_paths:\n",
    "        exam_results[exam_path] = load_exam_and_extract_text_words(\n",
    "            exam_path, write_files=True\n",
    "        )\n",
    "\n",
    "    return exam_results\n",
    "\n",
    "\n",
    "def serialize_all_code_areas(\n",
    "    exam_results: Dict[str, ExamResult], exam_path: str\n",
    ") -> None:\n",
    "    exam_result: ExamResult = exam_results[exam_path]\n",
    "\n",
    "    code_areas: Dict[int, List[CodeArea]] = {}\n",
    "    for page_result in exam_result.page_results:\n",
    "        code_areas[page_result.page_number] = page_result.code_areas\n",
    "\n",
    "    out_dir = os.path.join(\"test_data\", os.path.basename(exam_path.replace(\".pdf\", \"\")))\n",
    "    os.makedirs(\"test_data\", exist_ok=True)\n",
    "    with open(f\"{out_dir}-code_areas.json\", \"w\") as code_file:\n",
    "        json.dump(\n",
    "            {k: [x.model_dump() for x in v] for k, v in code_areas.items()},\n",
    "            code_file,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    with open(f\"{out_dir}-raw.json\", \"w\") as code_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                v.page_number: {\n",
    "                    \"raw\": v.raw_text,\n",
    "                    \"split\": v.raw_text.split(\"\\n\"),\n",
    "                    \"struct_definitions\": [\n",
    "                        x.model_dump() for x in v.struct_definitions\n",
    "                    ],\n",
    "                    \"code_areas\": [x.model_dump() for x in v.code_areas],\n",
    "                    \"macro_definitions\": [x.model_dump() for x in v.macro_definitions],\n",
    "                }\n",
    "                for v in exam_result.page_results\n",
    "            },\n",
    "            code_file,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "exam_results = get_all_exam_results()\n",
    "for exam_path in exam_results.keys():\n",
    "    serialize_all_code_areas(exam_results, exam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = regex.compile(\n",
    "    r\"\"\"\n",
    "        \\{                          # Opening brace\n",
    "        (?:\n",
    "            \\s*                     # Optional leading whitespace\n",
    "            (?:\n",
    "                //.*(?:\\n|$)        | # Single-line comment\n",
    "                for\\s*\\([^)]*\\)\\s*\\{\\s*\\}\\s*(?:\\n|$)  | # Empty for loop\n",
    "                while\\s*\\([^)]*\\)\\s*\\{\\s*\\}\\s*(?:\\n|$) | # Empty while loop\n",
    "            )\n",
    "        )*                           # Repeat for multiple lines\n",
    "        \\}                          # Closing brace\n",
    "        \"\"\",\n",
    "    regex.VERBOSE | regex.MULTILINE,\n",
    ")\n",
    "\n",
    "inputs = [\n",
    "    \"{ //complete this function \\n}\",\n",
    "    \"{ //complete this function \\n\\n}\",\n",
    "    \"{ //complete this function \\n\\n\\n}\",\n",
    "    \"{ //complete this function \\n\\n\\n\\n}\",\n",
    "    \"{ }\",\n",
    "    \"int kClosePerm(int* perm, int* used, int n, int maxgap, int k) {\\nif (n == k)  \\n ______________________ ; \\n int res = 0; \\n for (int i=0; i<n; i++) { \\n} \\n return res; \\n}\",  # should match ONLY the text within the empty for loop\n",
    "]\n",
    "\n",
    "for input in inputs:\n",
    "    matches = pattern.finditer(input)\n",
    "    print(f\"matches={matches}\")\n",
    "    for match in matches:\n",
    "        print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"\"\"struct tv_show * delete_show_list (struct tv_show *show_list, int length) { \n",
    "} \n",
    "Spring 2020 \n",
    "Data Structures Exam, Part A \n",
    " \n",
    "Page 3 of 4\"\"\",\n",
    "    \"\"\"node *deleteMe(node* head, node* me) { \\n}\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "my_pattern = regex.compile(\n",
    "    r\"\"\"\n",
    "    ^\\s*                                   # Ensure the function definition starts at a line (after optional indentation)\n",
    "    (?P<return_type>\n",
    "        [A-Za-z_*\\&\\[\\]]+                   # The first part of the return type (e.g., int, void, etc.), excluding digits\n",
    "        (?:\n",
    "            (?:\\s+|/\\*.*?\\*/|//.*?$)+        # Allow whitespace or comments between return type parts\n",
    "            [A-Za-z_*\\&\\[\\]]+               # Additional part of the return type (e.g., static, inline)\n",
    "        )*\n",
    "    )\n",
    "    \\s*                                    # Some whitespace after the return type before the function name\n",
    "    (?P<function_name>\\w+)                 # The function name\n",
    "    \\s*                                    # Optional whitespace before the arguments\n",
    "    \\(\n",
    "        (?P<arguments>\n",
    "            (?:[^()]*|\\((?:[^()]|\\([^()]*\\))*\\))*\n",
    "        )\n",
    "    \\)\\s*\n",
    "    (?P<body>\n",
    "        \\{\n",
    "            (?:\n",
    "                [^{}]+                     # Non-brace characters\n",
    "                |\n",
    "                (?&body)                   # Recursively match nested braces\n",
    "            )*\n",
    "        \\}\n",
    "    )\n",
    "    \"\"\",\n",
    "    regex.MULTILINE | regex.DOTALL | regex.VERBOSE,\n",
    ")\n",
    "\n",
    "for input in inputs:\n",
    "    matches = my_pattern.finditer(input)\n",
    "    print(f\"matches={matches}\")\n",
    "    for match in matches:\n",
    "        print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\n",
    "    r\"(?s)\\s*([1-5])\\)\\s*\\((\\d+)\\s*pts\\)\\s*([\\w/ ]+)\\s*\\(\\s*([^)]+?)\\s*\\)\\s*(.*?)(?=\\s*[1-5]\\)\\s*\\(\\d+\\s*pts\\)\\s*[\\w/ ]+\\s*\\([^)]+\\)|\\s*\\Z)\",\n",
    "    re.DOTALL,\n",
    ")\n",
    "\n",
    "inputs = [\n",
    "    \"2) (10 pts) ALG/DSN (Sorting) \\n \\n(a) (5 pts) Consider running a Bubble Sort on the array shown below. How many swaps will execute for\\nthe duration of the algorithm running on the array shown below? Explain how you got your answer. \\n97 \\n16 \\n45 \\n63 \\n13 \\n22 \\n7 \\n58 \\n72 \\nReasoning: \\nNumber of Swaps: _________ \\n(b) (5 pts) List the best case run time of each of the following sorting algorithms, in terms of n, the \\nnumber of items being sorted. Assume all items being sorted are distinct. \\n(i) Insertion Sort \\n \\n \\n \\n____________ \\n(ii) Selection Sort \\n \\n \\n \\n____________ \\n(iii) Heap Sort  \\n \\n \\n \\n____________ \\n(iv) Merge Sort \\n \\n \\n \\n____________ \\n(v) Quick Sort  \\n \\n \\n \\n____________ \\n\"\n",
    "]\n",
    "\n",
    "for input in inputs:\n",
    "    matches = pattern.findall(input)\n",
    "    print(f\"matches={matches}\")\n",
    "    for match in matches:\n",
    "        print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parser-2Aur3UYS-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
